{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "### Main Project 1 script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZUIDFL5jxvxe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "D7FSvO5_xvxj"
   },
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc',\n",
    "              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "              'rec.autos', 'rec.motorcycles',\n",
    "              'rec.sport.baseball', 'rec.sport.hockey']\n",
    "train_dataset = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "test_dataset = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ob_91Lq_xvxl"
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "0WEfap6yxvxm",
    "outputId": "dc8a8680-a3b7-420a-bb63-cb2aaf14810e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106346e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch all 20 news groups categories and plot a histogram of the training documents.\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "plt.hist(newsgroups_train.target, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIGvgdKMxvxr"
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PCUxRNaDxvxs"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Fetching 20NewsGroups dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Refer to the offcial document of scikit-learn for detailed usages:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n",
    "categories = ['comp.graphics', 'comp.sys.mac.hardware']\n",
    "twenty_train = fetch_20newsgroups(subset='train', # choose which subset of the dataset to use; can be 'train', 'test', 'all'\n",
    "                                  categories=categories, # choose the categories to load; if is `None`, load all categories\n",
    "                                  shuffle=True,\n",
    "                                  random_state=42, # set the seed of random number generator when shuffling to make the outcome repeatable across different runs\n",
    "                                  # remove=['headers'],\n",
    "                                  )\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y1Aq6iCbxvxu"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Perform lemmatization on dataset\n",
    "\n",
    "# The lemmatizer is actually pretty complicated, it needs Parts of Speech (POS) tags\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "# nltk.download('punkt')#, if you need \"tokenizers/punkt/english.pickle\", choose it\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN': 'n', 'JJ': 'a',\n",
    "                  'VB': 'v', 'RB': 'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "\n",
    "# def lemmatize_sent(list_word, wnl):\n",
    "#     # Text input is string, returns array of lowercased strings(words).\n",
    "#     return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag))\n",
    "#             for word, tag in pos_tag(list_word)]\n",
    "\n",
    "\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "def lemmatize_training(text):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag))\n",
    "            for word, tag in pos_tag(nltk.word_tokenize(text))]\n",
    "\n",
    "\n",
    "# TODO: should this filter out the following numbers too? \"4-5\" \"c650\"\n",
    "def filter_numbers(text_array):\n",
    "    # Filter out any numbers found in the array of strings\n",
    "    output = []\n",
    "    for s in text_array:\n",
    "        if not s.isdigit():\n",
    "            # if not a digit...\n",
    "            try:\n",
    "                # if a float, filter out\n",
    "                float(s)\n",
    "            except ValueError:\n",
    "                # if not a float, add to output\n",
    "                output.append(s)\n",
    "        else:\n",
    "            # if a digit, filter out\n",
    "            pass\n",
    "    return output\n",
    "\n",
    "\n",
    "def array_to_string(text_array, delimeter=\"\"):\n",
    "    # Converts an array back into a string of words using the provided delimeter to add between each word\n",
    "    output = \"\"\n",
    "    for s in text_array:\n",
    "        output = output + delimeter + s\n",
    "    return output\n",
    "\n",
    "\n",
    "def lemmatize_and_filter(documents):\n",
    "    # Performs lemmatization, and number filtering on the given documents\n",
    "    lemmatized_data = []\n",
    "    for i in documents:\n",
    "        # lemmatize the document:\n",
    "        training_tagged = pos_tag(nltk.word_tokenize(i))\n",
    "        lemmatized_array = lemmatize_training(i)\n",
    "\n",
    "        # remove numbers from document:\n",
    "        filtered_array = filter_numbers(lemmatized_array)\n",
    "\n",
    "        # reassemble back to string:\n",
    "        lemmatized_string = array_to_string(filtered_array, ' ')\n",
    "\n",
    "        # add to final data list\n",
    "        # print(lemmatized_string)\n",
    "        lemmatized_data.append(lemmatized_string)\n",
    "\n",
    "    return lemmatized_data\n",
    "\n",
    "\n",
    "# print(lemmatized_data[0])\n",
    "lemmatized_training = lemmatize_and_filter(twenty_train.data)\n",
    "lemmatized_testing = lemmatize_and_filter(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BjA770b7xvxw"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Push lemmatized documents through CountVectorizer\n",
    "\n",
    "# count_vect = CountVectorizer(min_df=3)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# do for training\n",
    "count_vect = CountVectorizer(min_df=3, stop_words='english')\n",
    "X_lemmatized_train_counts = count_vect.fit_transform(lemmatized_training)\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_counts = count_vect.transform(lemmatized_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "Z0Ju4BQ8xvxz",
    "outputId": "11b41fa6-8266-401a-90b7-f27aaf7151c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 5167)\n",
      "--------------------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.12043498 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "(774, 5167)\n",
      "--------------------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.14204286 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Report shapes of TF-IDF matrices\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# do for training\n",
    "X_lemmatized_train_tfidf = tfidf_transformer.fit_transform(X_lemmatized_train_counts)\n",
    "\n",
    "print(X_lemmatized_train_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_train_counts.toarray()[:30, :5])\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_train_tfidf.toarray()[:30, :5])\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_tfidf = tfidf_transformer.transform(X_lemmatized_test_counts)\n",
    "\n",
    "print(X_lemmatized_test_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_test_counts.toarray()[:30, :5])\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_test_tfidf.toarray()[:30, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "5o5ftdgBxvx3"
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "MVuiiQJoxvx3",
    "outputId": "a5da2dcb-8bc2-45d9-d9b2-aa949a9c6ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 50)\n",
      "(50, 5167)\n",
      "(1162, 50)\n",
      "(50, 5167)\n"
     ]
    }
   ],
   "source": [
    "# Perform LSI using the truncated SVD\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_lsi_train_reduced = svd.fit_transform(X_lemmatized_train_tfidf)\n",
    "Y_lsi_train_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)\n",
    "\n",
    "X_lsi_test_reduced = svd.transform(X_lemmatized_test_tfidf)\n",
    "Y_lsi_test_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "URSfInKOxvx6",
    "outputId": "d93fc1e9-0aac-4211-e920-12872703dde2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 50)\n",
      "(50, 5167)\n"
     ]
    }
   ],
   "source": [
    "# Perform NMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=50, init='random', random_state=42)\n",
    "W_nmf_train_reduced = model.fit_transform(X_lemmatized_train_tfidf)\n",
    "H_nmf_train_reduced = model.components_\n",
    "\n",
    "print(W_nmf_train_reduced.shape)\n",
    "print(H_nmf_train_reduced.shape)\n",
    "\n",
    "W_nmf_test_reduced = model.transform(X_lemmatized_test_tfidf)\n",
    "H_nmf_test_reduced = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "AfGbsKGhxvx-",
    "outputId": "9ebacd84-439f-4a77-e1dc-694ab155539b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF:  30.10726773762609\n",
      "LSI:  29.800199080327772\n"
     ]
    }
   ],
   "source": [
    "# Compare LSI and NMF\n",
    "\n",
    "nmf_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(W_nmf_train_reduced, H_nmf_train_reduced), 'fro')\n",
    "lsi_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(X_lsi_train_reduced, Y_lsi_train_reduced), 'fro')\n",
    "\n",
    "print('NMF: ', nmf_val)\n",
    "print('LSI: ', lsi_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train an unregularized logistic regression classifier.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# To be unregularized, we make the inverse of the regularization strength C \n",
    "# to be large to approximate an unregularized classifier.\n",
    "clf = LogisticRegression(random_state=42, C=500, solver='lbfgs').fit(X_lsi_train_reduced, twenty_train.target)\n",
    "\n",
    "# score = clf.decision_function(X_lsi_test_reduced)\n",
    "predicted = clf.predict(X_lsi_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[355  34]\n",
      " [ 12 373]]\n",
      "Accuracy:  0.9405684754521964\n",
      "Average precision-recall score: 0.9034007456840438\n",
      "Precision score:  0.9164619164619164\n",
      "Recall score:  0.9688311688311688\n",
      "F-1 score: 0.9419191919191919\n"
     ]
    }
   ],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion matrix: \\n', confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(twenty_test.target, predicted))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score: ', precision_score(twenty_test.target, predicted))\n",
    "print('Recall score: ', recall_score(twenty_test.target, predicted))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score:', f1_score(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ac6e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "score = clf.decision_function(X_lsi_test_reduced)\n",
    "fpr, tpr, thresholds = roc_curve(twenty_test.target, score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for unregularized logistic regression')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGNn6K_exvyB"
   },
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5NkfS2HZxvyB"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Train a Naive Bayes Gaussian classifier on the reduced TFIDF training set from problem 3\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = GaussianNB().fit(W_nmf_train_reduced, twenty_train.target)\n",
    "clf2 = MultinomialNB().fit(W_nmf_train_reduced, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "kQN9jIzvxvyE",
    "outputId": "6308ec42-fcf7-4348-a564-562c886cda29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics =? comp.graphics\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.graphics =? comp.sys.mac.hardware\n",
      "comp.graphics =? comp.sys.mac.hardware\n",
      "...\n",
      "\n",
      "Accuracy of NB Gaussian: 0.5568475452196382\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Generate predictions for test set\n",
    "\n",
    "predicted = clf.predict(W_nmf_test_reduced)\n",
    "correct = 0\n",
    "for i, category in enumerate(predicted):\n",
    "    if category == twenty_test.target[i]:\n",
    "        correct += 1\n",
    "    if i < 5:\n",
    "        print('{} =? {}'.format(twenty_test.target_names[category], twenty_test.target_names[twenty_test.target[i]]))\n",
    "    elif i == 5:\n",
    "        print('...\\n')\n",
    "print('Accuracy of NB Gaussian: {}'.format(correct / W_nmf_test_reduced.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "h0IChMnAxvyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics =? comp.graphics\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.graphics =? comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "...\n",
      "\n",
      "Accuracy of NB Gaussian: 0.5775193798449613\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Generate predictions for test set\n",
    "\n",
    "predicted = clf2.predict(W_nmf_test_reduced)\n",
    "correct = 0\n",
    "for i, category in enumerate(predicted):\n",
    "    if category == twenty_test.target[i]:\n",
    "        correct += 1\n",
    "    if i < 5:\n",
    "        print('{} =? {}'.format(twenty_test.target_names[category], twenty_test.target_names[twenty_test.target[i]]))\n",
    "    elif i == 5:\n",
    "        print('...\\n')\n",
    "print('Accuracy of NB Gaussian: {}'.format(correct / W_nmf_test_reduced.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wp2QQX5ByD0-"
   },
   "source": [
    "#### TEST"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "proj1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
