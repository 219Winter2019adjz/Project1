{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "### Main Project 1 script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZUIDFL5jxvxe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "D7FSvO5_xvxj"
   },
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc',\n",
    "              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "              'rec.autos', 'rec.motorcycles',\n",
    "              'rec.sport.baseball', 'rec.sport.hockey']\n",
    "train_dataset = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "test_dataset = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ob_91Lq_xvxl"
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WEfap6yxvxm",
    "outputId": "dc8a8680-a3b7-420a-bb63-cb2aaf14810e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25487e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch all 20 news groups categories and plot a histogram of the training documents.\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "plt.hist(newsgroups_train.target, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIGvgdKMxvxr"
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PCUxRNaDxvxs"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Fetching 20NewsGroups dataset\n",
    "twenty_train = fetch_20newsgroups(subset='train', # choose which subset of the dataset to use; can be 'train', 'test', 'all'\n",
    "                                  categories=categories, # choose the categories to load; if is `None`, load all categories\n",
    "                                  shuffle=True,\n",
    "                                  random_state=42, # set the seed of random number generator when shuffling to make the outcome repeatable across different runs\n",
    "                                  # remove=['headers'],\n",
    "                                  )\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1Aq6iCbxvxu"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2522e8486c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# print(lemmatized_data[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mlemmatized_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatize_and_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwenty_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mlemmatized_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatize_and_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwenty_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-2522e8486c55>\u001b[0m in \u001b[0;36mlemmatize_and_filter\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# lemmatize the document:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mtraining_tagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mlemmatized_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemmatize_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[1;32m    161\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtagged_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Maps to the specified tagset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eng'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mprev2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Do a secondary alphabetic sort, for stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Perform lemmatization on dataset\n",
    "\n",
    "# The lemmatizer is actually pretty complicated, it needs Parts of Speech (POS) tags\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "# nltk.download('punkt')#, if you need \"tokenizers/punkt/english.pickle\", choose it\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN': 'n', 'JJ': 'a',\n",
    "                  'VB': 'v', 'RB': 'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "\n",
    "# def lemmatize_sent(list_word, wnl):\n",
    "#     # Text input is string, returns array of lowercased strings(words).\n",
    "#     return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag))\n",
    "#             for word, tag in pos_tag(list_word)]\n",
    "\n",
    "\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "def lemmatize_training(text):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag))\n",
    "            for word, tag in pos_tag(nltk.word_tokenize(text))]\n",
    "\n",
    "\n",
    "# TODO: should this filter out the following numbers too? \"4-5\" \"c650\"\n",
    "def filter_numbers(text_array):\n",
    "    # Filter out any numbers found in the array of strings\n",
    "    output = []\n",
    "    for s in text_array:\n",
    "        if not s.isdigit():\n",
    "            # if not a digit...\n",
    "            try:\n",
    "                # if a float, filter out\n",
    "                float(s)\n",
    "            except ValueError:\n",
    "                # if not a float, add to output\n",
    "                output.append(s)\n",
    "        else:\n",
    "            # if a digit, filter out\n",
    "            pass\n",
    "    return output\n",
    "\n",
    "\n",
    "def array_to_string(text_array, delimeter=\"\"):\n",
    "    # Converts an array back into a string of words using the provided delimeter to add between each word\n",
    "    output = \"\"\n",
    "    for s in text_array:\n",
    "        output = output + delimeter + s\n",
    "    return output\n",
    "\n",
    "\n",
    "def lemmatize_and_filter(documents):\n",
    "    # Performs lemmatization, and number filtering on the given documents\n",
    "    lemmatized_data = []\n",
    "    for i in documents:\n",
    "        # lemmatize the document:\n",
    "        training_tagged = pos_tag(nltk.word_tokenize(i))\n",
    "        lemmatized_array = lemmatize_training(i)\n",
    "\n",
    "        # remove numbers from document:\n",
    "        filtered_array = filter_numbers(lemmatized_array)\n",
    "\n",
    "        # reassemble back to string:\n",
    "        lemmatized_string = array_to_string(filtered_array, ' ')\n",
    "\n",
    "        # add to final data list\n",
    "        # print(lemmatized_string)\n",
    "        lemmatized_data.append(lemmatized_string)\n",
    "\n",
    "    return lemmatized_data\n",
    "\n",
    "\n",
    "# print(lemmatized_data[0])\n",
    "lemmatized_training = lemmatize_and_filter(twenty_train.data)\n",
    "lemmatized_testing = lemmatize_and_filter(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BjA770b7xvxw"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Push lemmatized documents through CountVectorizer\n",
    "\n",
    "# count_vect = CountVectorizer(min_df=3)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# do for training\n",
    "count_vect = CountVectorizer(min_df=3, stop_words='english')\n",
    "X_lemmatized_train_counts = count_vect.fit_transform(lemmatized_training)\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_counts = count_vect.transform(lemmatized_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0Ju4BQ8xvxz",
    "outputId": "11b41fa6-8266-401a-90b7-f27aaf7151c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 5167)\n",
      "--------------------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.12043498 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "(774, 5167)\n",
      "--------------------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.14204286 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Report shapes of TF-IDF matrices\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# do for training\n",
    "X_lemmatized_train_tfidf = tfidf_transformer.fit_transform(X_lemmatized_train_counts)\n",
    "\n",
    "print(X_lemmatized_train_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_train_counts.toarray()[:30, :5])\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_train_tfidf.toarray()[:30, :5])\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_tfidf = tfidf_transformer.transform(X_lemmatized_test_counts)\n",
    "\n",
    "print(X_lemmatized_test_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_test_counts.toarray()[:30, :5])\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_test_tfidf.toarray()[:30, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "5o5ftdgBxvx3"
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVuiiQJoxvx3",
    "outputId": "a5da2dcb-8bc2-45d9-d9b2-aa949a9c6ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 50)\n",
      "(50, 5167)\n",
      "(1162, 50)\n",
      "(50, 5167)\n"
     ]
    }
   ],
   "source": [
    "# Perform LSI using the truncated SVD\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_lsi_train_reduced = svd.fit_transform(X_lemmatized_train_tfidf)\n",
    "Y_lsi_train_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)\n",
    "\n",
    "X_lsi_test_reduced = svd.transform(X_lemmatized_test_tfidf)\n",
    "Y_lsi_test_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URSfInKOxvx6",
    "outputId": "d93fc1e9-0aac-4211-e920-12872703dde2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 50)\n",
      "(50, 5167)\n"
     ]
    }
   ],
   "source": [
    "# Perform NMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=50, init='random', random_state=42)\n",
    "W_nmf_train_reduced = model.fit_transform(X_lemmatized_train_tfidf)\n",
    "H_nmf_train_reduced = model.components_\n",
    "\n",
    "print(W_nmf_train_reduced.shape)\n",
    "print(H_nmf_train_reduced.shape)\n",
    "\n",
    "W_nmf_test_reduced = model.transform(X_lemmatized_test_tfidf)\n",
    "H_nmf_test_reduced = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfGbsKGhxvx-",
    "outputId": "9ebacd84-439f-4a77-e1dc-694ab155539b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF:  30.107267737625925\n",
      "LSI:  29.800199080327467\n"
     ]
    }
   ],
   "source": [
    "# Compare LSI and NMF\n",
    "\n",
    "nmf_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(W_nmf_train_reduced, H_nmf_train_reduced), 'fro')\n",
    "lsi_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(X_lsi_train_reduced, Y_lsi_train_reduced), 'fro')\n",
    "\n",
    "print('NMF: ', nmf_val)\n",
    "print('LSI: ', lsi_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train an unregularized logistic regression classifier.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# To be unregularized, we make the inverse of the regularization strength C \n",
    "# to be large to approximate an unregularized classifier.\n",
    "clf = LogisticRegression(random_state=42, C=500, solver='lbfgs').fit(X_lsi_train_reduced, twenty_train.target)\n",
    "\n",
    "# score = clf.decision_function(X_lsi_test_reduced)\n",
    "predicted = clf.predict(X_lsi_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[355  34]\n",
      " [ 12 373]]\n",
      "Accuracy:  0.9405684754521964\n",
      "Average precision-recall score: 0.9034007456840438\n",
      "Precision score:  0.9164619164619164\n",
      "Recall score:  0.9688311688311688\n",
      "F-1 score: 0.9419191919191919\n"
     ]
    }
   ],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion matrix: \\n', confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(twenty_test.target, predicted))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score: ', precision_score(twenty_test.target, predicted))\n",
    "print('Recall score: ', recall_score(twenty_test.target, predicted))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score:', f1_score(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwgnpAD4XJoLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2527ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "score = clf.decision_function(X_lsi_test_reduced)\n",
    "fpr, tpr, thresholds = roc_curve(twenty_test.target, score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for unregularized logistic regression')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGNn6K_exvyB"
   },
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5NkfS2HZxvyB"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Train a Naive Bayes Gaussian classifier on the reduced TFIDF training set from problem 3\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = GaussianNB().fit(W_nmf_train_reduced, twenty_train.target)\n",
    "clf2 = MultinomialNB().fit(W_nmf_train_reduced, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQN9jIzvxvyE",
    "outputId": "6308ec42-fcf7-4348-a564-562c886cda29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics =? comp.graphics\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "...\n",
      "\n",
      "Accuracy of NB Gaussian: 0.917312661498708\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Generate predictions for test set\n",
    "\n",
    "predicted = clf.predict(W_nmf_test_reduced)\n",
    "correct = 0\n",
    "for i, category in enumerate(predicted):\n",
    "    if category == twenty_test.target[i]:\n",
    "        correct += 1\n",
    "    if i < 5:\n",
    "        print('{} =? {}'.format(twenty_test.target_names[category], twenty_test.target_names[twenty_test.target[i]]))\n",
    "    elif i == 5:\n",
    "        print('...\\n')\n",
    "print('Accuracy of NB Gaussian: {}'.format(correct / W_nmf_test_reduced.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0IChMnAxvyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics =? comp.graphics\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware =? comp.sys.mac.hardware\n",
      "comp.graphics =? comp.sys.mac.hardware\n",
      "...\n",
      "\n",
      "Accuracy of NB Gaussian: 0.9328165374677002\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Generate predictions for test set\n",
    "\n",
    "predicted = clf2.predict(W_nmf_test_reduced)\n",
    "correct = 0\n",
    "for i, category in enumerate(predicted):\n",
    "    if category == twenty_test.target[i]:\n",
    "        correct += 1\n",
    "    if i < 5:\n",
    "        print('{} =? {}'.format(twenty_test.target_names[category], twenty_test.target_names[twenty_test.target[i]]))\n",
    "    elif i == 5:\n",
    "        print('...\\n')\n",
    "print('Accuracy of NB Gaussian: {}'.format(correct / W_nmf_test_reduced.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wp2QQX5ByD0-"
   },
   "source": [
    "#### TEST"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "proj1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
