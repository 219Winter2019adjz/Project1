{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "### Main Project 1 script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUIDFL5jxvxe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7FSvO5_xvxj"
   },
   "outputs": [],
   "source": [
    "# categories = ['comp.graphics', 'comp.os.ms-windows.misc',\n",
    "#               'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "#               'rec.autos', 'rec.motorcycles',\n",
    "#               'rec.sport.baseball', 'rec.sport.hockey']\n",
    "# train_dataset = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "# test_dataset = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ob_91Lq_xvxl"
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WEfap6yxvxm",
    "outputId": "dc8a8680-a3b7-420a-bb63-cb2aaf14810e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch all 20 news groups categories and plot a histogram of the training documents.\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "plt.hist(newsgroups_train.target, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIGvgdKMxvxr"
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCUxRNaDxvxs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\scikit_learn_data\\20news_home\\20news-bydate-train\\comp.sys.mac.hardware\\51613\n",
      "3\n",
      "['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Fetching 20NewsGroups dataset\n",
    "\n",
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc',\n",
    "              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "              'rec.autos', 'rec.motorcycles',\n",
    "              'rec.sport.baseball', 'rec.sport.hockey']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', # choose which subset of the dataset to use; can be 'train', 'test', 'all'\n",
    "                                  categories=categories, # choose the categories to load; if is `None`, load all categories\n",
    "                                  shuffle=True,\n",
    "                                  random_state=42, # set the seed of random number generator when shuffling to make the outcome repeatable across different runs\n",
    "                                  # remove=['headers'],\n",
    "                                  )\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# Change labels into binary based on two well separated classes: Computer (labels 0-3) and Recreational (labels 4-7).\n",
    "twenty_train_binary_labels = np.zeros(len(twenty_train.target))\n",
    "for k in range(len(twenty_train.target)):\n",
    "    if twenty_train.target[k] >= 4:\n",
    "        twenty_train_binary_labels[k] = 1\n",
    "twenty_test_binary_labels = np.zeros(len(twenty_test.target))\n",
    "for k in range(len(twenty_test.target)):\n",
    "    if twenty_test.target[k] >= 4:\n",
    "        twenty_test_binary_labels[k] = 1\n",
    "        \n",
    "i = 51\n",
    "print(twenty_train.filenames[i])\n",
    "print(twenty_train.target[i])\n",
    "print(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1Aq6iCbxvxu"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Perform lemmatization on dataset\n",
    "\n",
    "# The lemmatizer is actually pretty complicated, it needs Parts of Speech (POS) tags\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "# nltk.download('punkt')#, if you need \"tokenizers/punkt/english.pickle\", choose it\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN': 'n', 'JJ': 'a',\n",
    "                  'VB': 'v', 'RB': 'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "\n",
    "# def lemmatize_sent(list_word, wnl):\n",
    "#     # Text input is string, returns array of lowercased strings(words).\n",
    "#     return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag))\n",
    "#             for word, tag in pos_tag(list_word)]\n",
    "\n",
    "\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "def lemmatize_training(text):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag))\n",
    "            for word, tag in pos_tag(nltk.word_tokenize(text))]\n",
    "\n",
    "\n",
    "# TODO: should this filter out the following numbers too? \"4-5\" \"c650\"\n",
    "def filter_numbers(text_array):\n",
    "    # Filter out any numbers found in the array of strings\n",
    "    output = []\n",
    "    for s in text_array:\n",
    "        if not s.isdigit():\n",
    "            # if not a digit...\n",
    "            try:\n",
    "                # if a float, filter out\n",
    "                float(s)\n",
    "            except ValueError:\n",
    "                # if not a float, add to output\n",
    "                output.append(s)\n",
    "        else:\n",
    "            # if a digit, filter out\n",
    "            pass\n",
    "    return output\n",
    "\n",
    "\n",
    "def array_to_string(text_array, delimeter=\"\"):\n",
    "    # Converts an array back into a string of words using the provided delimeter to add between each word\n",
    "    output = \"\"\n",
    "    for s in text_array:\n",
    "        output = output + delimeter + s\n",
    "    return output\n",
    "\n",
    "\n",
    "def lemmatize_and_filter(documents):\n",
    "    # Performs lemmatization, and number filtering on the given documents\n",
    "    lemmatized_data = []\n",
    "    for i in documents:\n",
    "        # lemmatize the document:\n",
    "        training_tagged = pos_tag(nltk.word_tokenize(i))\n",
    "        lemmatized_array = lemmatize_training(i)\n",
    "\n",
    "        # remove numbers from document:\n",
    "        filtered_array = filter_numbers(lemmatized_array)\n",
    "\n",
    "        # reassemble back to string:\n",
    "        lemmatized_string = array_to_string(filtered_array, ' ')\n",
    "\n",
    "        # add to final data list\n",
    "        # print(lemmatized_string)\n",
    "        lemmatized_data.append(lemmatized_string)\n",
    "\n",
    "    return lemmatized_data\n",
    "\n",
    "\n",
    "# print(lemmatized_data[0])\n",
    "lemmatized_training = lemmatize_and_filter(twenty_train.data)\n",
    "lemmatized_testing = lemmatize_and_filter(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjA770b7xvxw"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Push lemmatized documents through CountVectorizer\n",
    "\n",
    "# count_vect = CountVectorizer(min_df=3)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# do for training\n",
    "count_vect = CountVectorizer(min_df=3, stop_words='english')\n",
    "X_lemmatized_train_counts = count_vect.fit_transform(lemmatized_training)\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_counts = count_vect.transform(lemmatized_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0Ju4BQ8xvxz",
    "outputId": "11b41fa6-8266-401a-90b7-f27aaf7151c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4732, 17426)\n",
      "--------------------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "(3150, 17426)\n",
      "--------------------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.07367032 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Report shapes of TF-IDF matrices\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# do for training\n",
    "X_lemmatized_train_tfidf = tfidf_transformer.fit_transform(X_lemmatized_train_counts)\n",
    "\n",
    "print(X_lemmatized_train_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_train_counts.toarray()[:30, :5])\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_train_tfidf.toarray()[:30, :5])\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_tfidf = tfidf_transformer.transform(X_lemmatized_test_counts)\n",
    "\n",
    "print(X_lemmatized_test_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_test_counts.toarray()[:30, :5])\n",
    "print('-' * 20)\n",
    "print(X_lemmatized_test_tfidf.toarray()[:30, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "5o5ftdgBxvx3"
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVuiiQJoxvx3",
    "outputId": "a5da2dcb-8bc2-45d9-d9b2-aa949a9c6ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4732, 50)\n",
      "(50, 17426)\n",
      "(4732, 50)\n",
      "(50, 17426)\n"
     ]
    }
   ],
   "source": [
    "# Perform LSI using the truncated SVD\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_lsi_train_reduced = svd.fit_transform(X_lemmatized_train_tfidf)\n",
    "Y_lsi_train_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)\n",
    "\n",
    "X_lsi_test_reduced = svd.transform(X_lemmatized_test_tfidf)\n",
    "Y_lsi_test_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URSfInKOxvx6",
    "outputId": "d93fc1e9-0aac-4211-e920-12872703dde2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4732, 50)\n",
      "(50, 17426)\n"
     ]
    }
   ],
   "source": [
    "# Perform NMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=50, init='random', random_state=42)\n",
    "W_nmf_train_reduced = model.fit_transform(X_lemmatized_train_tfidf)\n",
    "H_nmf_train_reduced = model.components_\n",
    "\n",
    "print(W_nmf_train_reduced.shape)\n",
    "print(H_nmf_train_reduced.shape)\n",
    "\n",
    "W_nmf_test_reduced = model.transform(X_lemmatized_test_tfidf)\n",
    "H_nmf_test_reduced = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfGbsKGhxvx-",
    "outputId": "9ebacd84-439f-4a77-e1dc-694ab155539b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF:  4156.105069008998\n",
      "LSI:  4119.970801953944\n"
     ]
    }
   ],
   "source": [
    "# Compare LSI and NMF\n",
    "\n",
    "nmf_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(W_nmf_train_reduced, H_nmf_train_reduced), 'fro')**2\n",
    "lsi_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(X_lsi_train_reduced, Y_lsi_train_reduced), 'fro')**2\n",
    "\n",
    "print('NMF: ', nmf_val)\n",
    "print('LSI: ', lsi_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an unregularized logistic regression classifier.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# To be unregularized, we make the inverse of the regularization strength C \n",
    "# to be large to approximate an unregularized classifier.\n",
    "clf = LogisticRegression(random_state=42, C=500, max_iter=100, solver='lbfgs').fit(X_lsi_train_reduced, twenty_train_binary_labels)\n",
    "\n",
    "# score = clf.decision_function(X_lsi_test_reduced)\n",
    "predicted = clf.predict(X_lsi_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[1508   52]\n",
      " [  35 1555]]\n",
      "Accuracy:  0.9723809523809523\n",
      "Precision score:  0.9676415681393902\n",
      "Recall score:  0.9779874213836478\n",
      "F-1 score: 0.9727869878010635\n"
     ]
    }
   ],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Confusion matrix: \\n', confusion_matrix(twenty_test_binary_labels, predicted))\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(twenty_test_binary_labels, predicted))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score: ', precision_score(twenty_test_binary_labels, predicted))\n",
    "print('Recall score: ', recall_score(twenty_test_binary_labels, predicted))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score:', f1_score(twenty_test_binary_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "score = clf.decision_function(X_lsi_test_reduced)\n",
    "fpr, tpr, thresholds = roc_curve(twenty_test_binary_labels, score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for unregularized logistic regression')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal regularization strength for L1 Regulation:  [0.1]\n",
      "Accuracy with L1 Regulation for L1 Regulation:  0.973015873015873\n",
      "Average precision-recall score for L1 Regulation: 0.957519138728885\n",
      "Precision score for L1 Regulation:  0.9665220086794792\n",
      "Recall score for L1 Regulation:  0.980503144654088\n",
      "F-1 score for L1 Regulation: 0.9734623790196691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1917: ChangedBehaviorWarning: The long-standing behavior to use the accuracy score has changed. The scoring parameter is now used. This warning will disappear in version 0.22.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3XmYHVW57/HvLwlhkDCZoJCBMGPgegAjoOAhMhkQEvFBBC8KMh0HBIeDgCgiDiiIKEcU41FBNEDAI0QEcWCSIYFwgABBrpExDBIGYwAZAu/9Y60uKju7uyudXXunO7/P8/TTNe2qd1XtXW/VWjUoIjAzMwMY1OkAzMxs+eGkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSsIKSn0l6VtItnY5neSBprKSQNKSPn3+XpPtqiCskbdLq+fawvD6XQ9KVkg5udUzLO0nnSPpSp+NYWit8UpD0oKR/SXpO0hOSzpW0esM075R0taSFkhZI+o2kcQ3TrCHpu5IezvOam/uHt7dEy2QnYHdgVERst6wz62mHKmkrSVdJekpSrzfL5Pk8n9fto5K+I2nwssZYt4j4c0Rs3s5lSrpW0uGtnGfVckg6WdIvGj67Z0Sct7TL7K/bvEtEfCwivtrpOJbWCp8Usn0iYnVga2Ab4ISuEZLeAfweuAxYH9gQuBO4UdJGeZqhwJ+ALYGJwBrAO4GngWXeuXanr0evPdgAeDAinm9DLK8A04DDluIz/5a3087AB4FDl3KZbVXD9lkR1b7N8xmy94VdImKF/gMeBHYr9Z8G/LbU/2fgB00+dyXw89x9OPB3YPWlWO6WwB+AZ/Jnv5CHnwt8rTTdBGBeQ7zHAbOBl4AvApc0zPt7wFm5e03gJ8DjwKPA14DBTeI5DHgReBV4DvhKHn4EMDfHOR1Yv/SZAD4J/BV4oMk8x+ZphvSwHjZJX8Ne11cAm5T6pwFnl/q7LScwGDgDeAp4ADiqHFeT78DJwC+alQH4KHAvsBC4H/iPxm2Vt88TwPnl7UfaqT1X+nsJuDaPWxn4NvBw/j6cA6xamvexuWyPkXaMi62PhnV1LXB4N+MmAfcA/8jTvaU0blvg9ly2i4GLyN9FlvweHpfX80LgPmBX0gHRy6SE/xxwZ7N48neqax3OAbbtwDa/Fvg6cCPwL9L3sKf5bQJcByzI87woDxdwJvBkHjcb2Kqb33Jvv6WPkX5LzwJnA6pjn9frb60TC12e/ijtEIBRwF3A93L/aqSd5LubfO6jwOO5+0LgvKVY5rD8xfscsEru376bL1Ljj/FB4A5gNLAq6ej+BWCN0o/hcWCH3H8p8CPgDcC6wC2UdmQNcR0C3FDq3yX/ALYl7bT+C7i+4Yv8B2AdSjuw0vix1JAUgC1yGT9TGt9tOfOPbU7evmsDf6TvSeG9wMakncHOed1vW9pWi4Bv5fW1auP2Ky1jDdKOsSvG75J2FOvk78NvgFPzuImkRLFVLt9U+pAUgM2A50lVhCsBnyftpIbmv4eAY/K495N28EskBWBz4BHyTi2vo40b112zeIAPkHa4b8/rcBNggw5s82tJCXhLYEguc0/zuwA4kVS7sgqwUx7+HuA2YK1cnrcA6zX+lqn2W7o8z2cMMB+Y2K794GLrvRMLXZ7+SDuE50hHLUGqBlorjxuVh23R5HMTgVdy9x+Aby7FMg8Ebu9mXPFFyv3Fj7EU76ENn7kB+Eju3h34W+5+E+lodNWGZV/TzbIPYfGk8BPgtFL/6qSjwLG5P4BdeijnWFqbFP5J2qlF/pGuXKWcwNUsfkS/G31MCk3iuhQ4prStXgZW6W775WGD8g7gh7lfuVwbl6Z5B/nsC/hp+ftF2rn3JSl8CZjWEMejOcZ/z90qjb+B5klhE9KR8W7ASg3LKNZds3iAq7rWV4e3+bXAKaXxvc3v58AUUntbOcZdgP8H7AAM6u63TLXf0k6l8dOA46usp1b/uR4teV9EDCN98bcAuhqHnwVeA9Zr8pn1SJkfUttBs2m6Mxr4W58iTR5p6J9K+gIDfCj3QzqLWAl4XNI/JP2DdCS0bsXlrE86egQgIp4jlXVkD7HUaVvSj+mDwPakIzrovZzrN8TZ55gl7SlphqRn8nL24vXvC8D8iHixl9l8nXQ2cHTuH0E6K72tFP/v8vBm8T9E3zRuz9fyfEfmcY9G3iNlTddTRMwFPk1KAE9KulDS+hVjWNrvfp3bvDyst/l9npS8b5F0j6RDASLiauD7pOqev0uaImmNJsuq8lt6otT9Qi532zkplETEdaTs/u3c/zxwM+mUt9H+pLMKSKem75H0hibTNfMIqQqimedJO4gub24WakP/xcAESaOAfXk9KTxCOvoZHhFr5b81ImLLinE+RvqxAJDL90bSEWV3sdQqkmmk7XJSHtxbOR8nnfV1Gd0w2yrrHEkrA78ifT/eFBFrAVeQdhZFiD3FL+kAUgLfLyJeyYOfItVrb1mKf81IDaxd8ZdjHtPTMnrQuD2V5/toXsbIPKxL43oqRMTUiNgpzy9IVWbQ+/ehp+9+d8uqY5s3xtrj/CLiiYg4IiLWB/4D+EHXJcERcVZEvI1UFbUZqf2nUZXf0nLBSWFJ3wV2l7R17j8eOFjS0ZKGSVpb0tdIp/dfydOcT/pS/UrSFpIGSXqjpC9I2qvJMi4H3izp05JWzvPdPo+7A9hL0jqS3kw6IutRRMwnnQ7/jFTlcG8e/jjpyqkz8iWzgyRtLGnniutiKvBRSVvnHeI3gJkR8WDFz3dZWdIqpb9B+YqPVUh12eThKy/FPL8JHCnpzRXKOQ04RtJISWuRGknL7gAOkLSSpPHAft0scyipPng+sEjSnsAeVQOWtA2pLvl9eZsBxRH7j4EzJa2bpx0p6T2l+A+RNE7SasCXKyxuSMM6XynP572Sds39nyPtCG8i7XBfBY6SNETSZLq5ck7S5pJ2ydvrRVJCezWP/jswtoeref4b+E9Jb8vfgU0kbdDNtI1auc0X09v8JH0gH3RBqkEI4FVJb5e0fV6fz/P6xRqNWvVbqp2TQoP8Y/05qf6ViLiB1Jj0ftLRx0Oky1Z3ioi/5mleItVZ/oXUvvBPUiPVcGBmk2UsJNX970M6Zfwr8O48+nzSJa8Pkr6kF1UMfWqOYWrD8I+QdmZzSF/mS6hY1RURfyKth1+Ryr4xcEDFeMqeI+04uv52IR01/Yt0JQy5u/LNURFxF+lqkK6jsp7K+WPSupxNurrmClKDcNeP90uksj1LSvSN67BrmQtJVT7T8rQfIjUOVzWZ1Oh5g9K1989JujKPO47U6DtD0j9JZ5+b5+VeSTpYuTpPc3WFZf2Qxdf5zyLiPuAgUmJ6ivT92yciXo6Il0nf8cNIVyYdRDp4eanJvFcm7aCfIn1/1wW+kMddnP8/Lel/Gz8YEReTqs+mktrxLiU1rveqxdu8mZ7m93ZgpqTnSNv8mIh4gHTBwI/z9A+RqoS+3ST2Vv2WaqfFqxDNBr58hH9ORFQ9Ql0hSZpJWk8/63Qsy8rbvDqfKdiAJ2lVSXvlapGRpOqXX3c6ruWNpJ0lvTmvp4OBt5IavPsdb/O+c1KwFYFI1ULPkqoS7uX1Bkt73eakqssFpPaG/XJde3/kbd5Hrj4yM7OCzxTMzKzQ7x7YNXz48Bg7dmynwzAz61duu+22pyJiRG/T9bukMHbsWGbNmtXpMMzM+hVJle6Ed/WRmZkVnBTMzKzgpGBmZgUnBTMzKzgpmJlZobakIOmnkp6UdHc34yXpLKUX3M+WtG1dsZiZWTV1nimcS3o7WXf2BDbNf0eSnupoZmYdVNt9ChFxvaSxPUwymfTi+yA9LngtSev142ettMzUmQ9z2R3L3bs3zKyDxq2/Bl/ep+r7sfqukzevjWTx1+HNy8OWSAqSjiSdTTBmTF9fOtV37d5Jz3zgGQC237DSY+bNzFqmk0lBTYY1fTpfREwhvTSb8ePHt/QJflV2+O3eSW+/4TpM3nokH9q+/QnQzFZsnUwK81j8vamjSO8xrVVjEqiyw/dO2sxWFJ1MCtNJ74O9ENgeWFBXe0I5ETQmAe/wzcxeV1tSkHQBMAEYLmke6c1HKwFExDmkd6buRXrn7AvAR1sdQ1cyKCcCJwEzs+7VefXRgb2MD+CTdS1/6syH+cKv7wJ8NmBmVlW/e3R2FeWE8I19/4+TgZlZRQPuMRdOCGZmfTfgkkJXg7ITgpnZ0htQSWHqzIeZ+cAzbL/hOk4IZmZ9MKCSQtdZwuStR3Y4EjOz/mlAJQXAZwlmZstgwCUFMzPrOycFMzMrDJik0NXIbGZmfTdgkoIbmc3Mlt2ASQrgRmYzs2U1IJKCq47MzFpjQCQFVx2ZmbXGgEgK4KojM7NWGDBJwczMlp2TgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWaHfJwXfuGZm1jr9Pin4xjUzs9bp90kBfOOamVmrDIikYGZmreGkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVak0KkiZKuk/SXEnHNxk/RtI1km6XNFvSXnXGY2ZmPastKUgaDJwN7AmMAw6UNK5hsi8C0yJiG+AA4Ad1xWNmZr2r80xhO2BuRNwfES8DFwKTG6YJYI3cvSbwWI3xmJlZL+pMCiOBR0r98/KwspOBgyTNA64APtVsRpKOlDRL0qz58+fXEauZmVFvUlCTYdHQfyBwbkSMAvYCzpe0REwRMSUixkfE+BEjRhTD/dhsM7PWqjMpzANGl/pHsWT10GHANICIuBlYBRhedQF+bLaZWWvVmRRuBTaVtKGkoaSG5OkN0zwM7Aog6S2kpLBU9UN+bLaZWevUlhQiYhFwFHAVcC/pKqN7JJ0iaVKe7HPAEZLuBC4ADomIxiomMzNrkyF1zjwiriA1IJeHnVTqngPsWGcMZmZWne9oNjOzgpOCmZkVnBTMzKzgpGBmZoV+mxR845qZWev126TgG9fMzFqv3yYF8I1rZmat1q+TgpmZtZaTgpmZFZwUzMys4KRgZmYFJwUzMyv0mhSUHCTppNw/RtJ29YdmZmbtVuVM4QfAO0hvSQNYCJxdW0RmZtYxVR6dvX1EbCvpdoCIeDa/NMfMzAaYKmcKr0gaTH6/sqQRwGu1RmVmZh1RJSmcBfwaWFfS14EbgFNrjcrMzDqi1+qjiPilpNtI71IW8L6IuLf2yMzMrO16TQqSzo+IDwN/aTLMzMwGkCrVR1uWe3L7wtvqCcfMzDqp26Qg6QRJC4G3SvqnpIW5/0ngsrZFaGZmbdNtUoiIUyNiGHB6RKwREcPy3xsj4oQ2xmhmZm1SpaH5BElrA5sCq5SGX19nYGZm1n5VGpoPB44BRgF3ADsANwO71BuamZm1W5WG5mOAtwMPRcS7gW2A+bVGZWZmHVElKbwYES8CSFo5Iv4CbF5vWGZm1glVnn00T9JawKXAHyQ9CzxWb1hmZtYJVRqa982dJ0u6BlgT+F2tUZmZWUf0mBQkDQJmR8RWABFxXVuiMjOzjuixTSEiXgPulDSmTfGYmVkHVWloXg+4R9KfJE3v+qsyc0kTJd0naa6k47uZZn9JcyTdI2nq0gRvZmatVaWh+St9mXF+RtLZwO7APOBWSdMjYk5pmk2BE4Ad88t71u3LsszMrDWqNDT3tR1hO2BuRNwPIOlCYDIwpzTNEcDZEfFsXtaTfVyWmZm1QJXqo74aCTxS6p+Xh5VtBmwm6UZJMyRNbDYjSUdKmiVp1vz5vm/OzKwudSYFNRkWDf1DSM9UmgAcCPx3vidi8Q9FTImI8RExfsSIES0P1MzMkkpJQdKqkpb2LuZ5wOhS/yiWvOltHnBZRLwSEQ8A95GShJmZdUCvSUHSPqQH4f0u929d8eqjW4FNJW0oaShwAND4uUuBd+f5DidVJ91fPXwzM2ulKmcKJ5Majf8BEBF3AGN7+1BELAKOAq4C7gWmRcQ9kk6RNClPdhXwtKQ5wDXAsRHx9NIWwszMWqPKJamLImKB1KyJoGcRcQVwRcOwk0rdAXw2/5mZWYdVSQp3S/oQMDjfV3A0cFO9YZmZWSdUqT76FLAl8BIwFVgAfLrOoMzMrDOqnClsHhEnAifWHYyZmXVWlTOF70j6i6SvStqy9ojMzKxjek0K+RWcE0iv4Jwi6S5JX6w7MDMza79KN69FxBMRcRbwMdI9Cyf18hEzM+uHqty89hZJJ0u6G/g+6cqjUbVHZmZmbVeloflnwAXAHhHhdzObmQ1gVR6dvUM7AjEzs87rNilImhYR+0u6i8WfbirSzchvrT06MzNrq57OFI7J//duRyBmZtZ53TY0R8TjufMTEfFQ+Q/4RHvCMzOzdqpySeruTYbt2epAzMys83pqU/g46YxgI0mzS6OGATfWHZiZmbVfT20KU4ErgVOB40vDF0bEM7VGZWZmHdFTUoiIeFDSJxtHSFrHicHMbODp7Uxhb+A20iWp5bfsBLBRjXGZmVkHdJsUImLv/H/D9oVjZmadVOXZRztKekPuPkjSdySNqT80MzNrtyqXpP4QeEHSvwGfBx4Czq81KjMz64gqSWFRRAQwGfheRHyPdFmqmZkNMFWekrpQ0gnAh4F3SRoMrFRvWGZm1glVzhQ+CLwEHBoRTwAjgdNrjcrMzDqiyus4nwB+CawpaW/gxYj4ee2RmZlZ21W5+mh/4BbgA8D+wExJ+9UdmJmZtV+VNoUTgbdHxJMAkkYAfwQuqTMwMzNrvyptCoO6EkL2dMXPmZlZP1PlTOF3kq4ivacZUsPzFfWFZGZmnVLlHc3HSno/sBPp+UdTIuLXtUdmZmZtV+VMAeAm4FXgNeDW+sIxM7NOqnL10eGkq4/2BfYDZkg6tO7AzMys/ao0GB8LbBMRh0TEwcDbgOOqzFzSREn3SZor6fgepttPUkgaXy1sMzOrQ5WkMA9YWOpfCDzS24fy4zDOJr3PeRxwoKRxTaYbBhwNzKwSsJmZ1adKUniUdMPayZK+DMwA5kr6rKTP9vC57YC5EXF/RLwMXEh6qF6jrwKnAS8uZexmZtZiVZLC34BLSW9bA7gMeJz0pNSenpY6ksXPKOblYQVJ2wCjI+LyngKQdKSkWZJmzZ8/v0LIZmbWF1UuSf1KH+etJsOiGCkNAs4EDqkQwxRgCsD48eOjl8nNzKyP6rwzeR4wutQ/Cnis1D8M2Aq4VtKDwA7AdDc2m5l1Tp1J4VZgU0kbShoKHABM7xoZEQsiYnhEjI2IsaS2ikkRMavGmMzMrAe1JYWIWAQcBVwF3AtMi4h7JJ0iaVJdyzUzs77rtU1B0mak9zS/KSK2kvRW0hH913r7bERcQcNzkiLipG6mnVApYjMzq02VM4UfAycArwBExGxSVZCZmQ0wVZLCahFxS8OwRXUEY2ZmnVUlKTwlaWPy5aT5rWuP1xqVmZl1RJWnpH6SdI/AFpIeBR4ADqo1KjMz64gqN6/dD+wm6Q2kt7At7O0zZmbWP1W5+uikhn4AIuKUmmIyM7MOqVJ99HypexVgb9J9B2ZmNsBUqT46o9wv6duU7kw2M7OBoy93NK8GbNTqQMzMrPOqtCncxetPNx0MjADcnmBmNgBVaVPYu9S9CPh7fq6RmZkNMD0mhfzOg99GxFZtisfMzDqoxzaFiHgNuFPSmDbFY2ZmHVSl+mg94B5Jt1C6PDUi/PhrM7MBpkpS6OvrOM3MrJ+pkhT2iojjygMkfQu4rp6QzMysU6rcp7B7k2F7tjoQMzPrvG7PFCR9HPgEsJGk2aVRw4Ab6w7MzMzar6fqo6nAlcCpwPGl4Qsj4plaozIzs47oNilExAJgAXBg+8IxM7NO6suzj8zMbIByUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFIwM7NCrUlB0kRJ90maK+n4JuM/K2mOpNmS/iRpgzrjMTOzntWWFCQNBs4mPWZ7HHCgpHENk90OjI+ItwKXAKfVFY+ZmfWuzjOF7YC5EXF/RLwMXAhMLk8QEddExAu5dwYwqsZ4zMysF3UmhZHAI6X+eXlYdw4jPap7CZKOlDRL0qz58+e3MEQzMyurMymoybBoOqF0EDAeOL3Z+IiYEhHjI2L8iBEjWhiimZmVVXlHc1/NA0aX+kcBjzVOJGk34ERg54h4qcZ4zMysF3WeKdwKbCppQ0lDgQOA6eUJJG0D/AiYFBFP1hiLmZlVUFtSiIhFwFHAVcC9wLSIuEfSKZIm5clOB1YHLpZ0h6Tp3czOzMzaoM7qIyLiCuCKhmEnlbp3q3P5Zma2dHxHs5mZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFIwM7OCk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzKzgpmJlZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWqDUpSJoo6T5JcyUd32T8ypIuyuNnShpbZzxmZtaz2pKCpMHA2cCewDjgQEnjGiY7DHg2IjYBzgS+VVc8ZmbWuzrPFLYD5kbE/RHxMnAhMLlhmsnAebn7EmBXSaoxJjMz68GQGuc9Enik1D8P2L67aSJikaQFwBuBp8oTSToSOBJgzJgxAIxbf41agjYzW5HVmRSaHfFHH6YhIqYAUwDGjx8fAF/eZ8tljc/MzBrUWX00Dxhd6h8FPNbdNJKGAGsCz9QYk5mZ9aDOpHArsKmkDSUNBQ4ApjdMMx04OHfvB1wdEUucKZiZWXvUVn2U2wiOAq4CBgM/jYh7JJ0CzIqI6cBPgPMlzSWdIRxQVzxmZta7OtsUiIgrgCsahp1U6n4R+ECdMZiZWXW+o9nMzApOCmZmVnBSMDOzgpOCmZkV1N+uAJU0H3go9w6n4e7nFciKXHZYscvvsq+YlrXsG0TEiN4m6ndJoUzSrIgY3+k4OmFFLjus2OV32V32Orn6yMzMCk4KZmZW6O9JYUqnA+igFbnssGKX32VfMbWl7P26TcHMzFqrv58pmJlZCzkpmJlZoV8kBUkTJd0naa6k45uMX1nSRXn8TElj2x9lPSqU/bOS5kiaLelPkjboRJx16K3spen2kxSSBsylilXKLmn/vO3vkTS13THWqcL3foykayTdnr/7e3UizlaT9FNJT0q6u5vxknRWXi+zJW3b8iAiYrn+Iz12+2/ARsBQ4E5gXMM0nwDOyd0HABd1Ou42lv3dwGq5++MrUtnzdMOA64EZwPhOx93G7b4pcDuwdu5ft9Nxt7n8U4CP5+5xwIOdjrtFZf93YFvg7m7G7wVcSXpr5Q7AzFbH0B/OFLYD5kbE/RHxMnAhMLlhmsnAebn7EmBXSc1e9dnf9Fr2iLgmIl7IvTNIb7gbCKpsd4CvAqcBL7YzuJpVKfsRwNkR8SxARDzZ5hjrVKX8AXS9qH1NlnyrY78UEdfT89snJwM/j2QGsJak9VoZQ39ICiOBR0r98/KwptNExCJgAfDGtkRXryplLzuMdBQxEPRadknbAKMj4vJ2BtYGVbb7ZsBmkm6UNEPSxLZFV78q5T8ZOEjSPNI7Wz7VntA6bmn3CUut1pfstEizI/7G62irTNMfVS6XpIOA8cDOtUbUPj2WXdIg4EzgkHYF1EZVtvsQUhXSBNLZ4Z8lbRUR/6g5tnaoUv4DgXMj4gxJ7yC9wXGriHit/vA6qvZ9XX84U5gHjC71j2LJU8ViGklDSKeTPZ2C9RdVyo6k3YATgUkR8VKbYqtbb2UfBmwFXCvpQVL96vQB0thc9Tt/WUS8EhEPAPeRksRAUKX8hwHTACLiZmAV0gPjBrpK+4Rl0R+Swq3AppI2lDSU1JA8vWGa6cDBuXs/4OrIrTL9XK9lz1UoPyIlhIFUr9xj2SNiQUQMj4ixETGW1J4yKSJmdSbclqrynb+UdJEBkoaTqpPub2uU9alS/oeBXQEkvYWUFOa3NcrOmA58JF+FtAOwICIeb+UClvvqo4hYJOko4CrSVQk/jYh7JJ0CzIqI6cBPSKePc0lnCAd0LuLWqVj204HVgYtz2/rDETGpY0G3SMWyD0gVy34VsIekOcCrwLER8XTnom6diuX/HPBjSZ8hVZ8cMhAOBCVdQKoSHJ7bS74MrAQQEeeQ2k/2AuYCLwAfbXkMA2A9mplZi/SH6iMzM2sTJwUzMys4KZiZWcFJwczMCk4KZmZWcFKw5ZqkoyXdK+mXPUwzQdJy8agLSZO6nuop6X2SxpXGnZJvNGxXLBMkvbNdy7OBYbm/T8FWeJ8A9sx37S738jX0XfdQvA+4HJiTx53U6uVJGpKf99XMBOA54KZWL9cGLp8p2HJL0jmkxydPl/QZSdtJuik/Q/8mSZs3+czOku7If7dLGpaHHyvp1vwM+q90s7znJJ0h6X/zuylG5OFb54fOzZb0a0lr5+FH6/V3WVyYhx0i6fv5CH0ScHqOZWNJ5yq9+2FPSdNKy50g6Te5ew9JN+cYLpa0epM4r5X0DUnXAcdI2kfpPSK3S/qjpDcpvVPkY8Bn8vLfJWmEpF/l9XCrpB2XYfPYQNXp54f7z389/QEPAsNz9xrAkNy9G/Cr3D0BuDx3/wbYMXevTjob3oP0/H2RDoQuB/69ybIC+L+5+yTg+7l7NrBz7j4F+G7ufgxYOXevlf8fUvrcucB+pfmfS3oMyxDSYxrekIf/EDiI9Oye60vDjwNOahLntcAPSv1r8/qNqIcDZ+Tuk4H/LE03Fdgpd48B7u309vXf8vfn6iPrT9YEzpO0KWkHvlKTaW4EvpPbIP4nIuZJ2oOUGG7P06xOenjc9Q2ffQ24KHf/AvgfSWuSdvjX5eHnARfn7tnALyVdSnoWUSWRHuPwO2AfSZcA7wU+T3rC7TjgxvzIkqHAzd3M5qJS9yjgIqXn6g8Fuqtq2w0Yp9dfNbKGpGERsbBq7DbwOSlYf/JV4JqI2DdXj1zbOEFEfFPSb0nPh5mRG3YFnBoRP1rK5fX2DJj3kt6UNQn4kqQtl2LeFwGfJD2r69aIWKi0t/5DRBxY4fPPl7r/C/hDyIAYAAABVElEQVROREyXNIF0htDMIOAdEfGvpYjTVjBuU7D+ZE3g0dx9SLMJJG0cEXdFxLeAWcAWpAerHdpVPy9ppKR1m3x8EKl6B+BDwA0RsQB4VtK78vAPA9cpvc9hdERcQzrKX4t0BlK2kPSI72auJb128QheP+qfAewoaZMc52qSNuvm82Xl9XJwaXjj8n8PHNXVI2nrCvO2FYyTgvUnpwGnSrqR9PTMZj4t6W5JdwL/Aq6MiN+T6tNvlnQX6ZWtzXbWzwNbSroN2IXUfgBpR3u6pNnA1nn4YOAXeX63A2fGki+4uRA4NjcAb1weERGvkto29sz/iYj5pGR3QV7WDFJS683JpKfk/hl4qjT8N8C+XQ3NwNHA+NwwPofUEG22GD8l1SyT9FxELHG1j9mKxGcKZmZW8JmCmZkVfKZgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZW+P+35YObyGqmsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal regularization strength for L2 regulation:  [0.01]\n",
      "Accuracy with L2 Regulation:  0.9733333333333334\n",
      "Average precision-recall score for L2 Regulation: 0.9581070282257136\n",
      "Precision score for L2 Regulation:  0.96712158808933\n",
      "Recall score for L2 Regulation:  0.980503144654088\n",
      "F-1 score for L2 Regulation: 0.9737663960024984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1917: ChangedBehaviorWarning: The long-standing behavior to use the accuracy score has changed. The scoring parameter is now used. This warning will disappear in version 0.22.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Define training and testing data sets\n",
    "X_train = X_lsi_train_reduced\n",
    "y_train = twenty_train_binary_labels\n",
    "\n",
    "X_test = X_lsi_test_reduced\n",
    "y_test = twenty_test_binary_labels\n",
    "\n",
    "# Define regularization strength values here\n",
    "REG_STRENGTH_OPTIONS = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# Determine regulation strength for L1 regulation\n",
    "clf_L1 = LogisticRegressionCV(random_state=42, Cs=REG_STRENGTH_OPTIONS, cv=5, penalty='l1', scoring='accuracy', solver = 'liblinear').fit(X_train, y_train)\n",
    "l1_reg_strength = 1/clf_L1.C_ # Regulization strength is inverse of optimal Cs\n",
    "predicted_L1 = clf_L1.predict(X_test)\n",
    "\n",
    "# Display L1 Stats\n",
    "print('Optimal regularization strength for L1 Regulation: ', l1_reg_strength)\n",
    "print('Accuracy with L1 Regulation for L1 Regulation: ', clf_L1.score(X_test, y_test))\n",
    "print('Average precision-recall score for L1 Regulation:', average_precision_score(y_test, predicted_L1))\n",
    "print('Precision score for L1 Regulation: ', precision_score(y_test, predicted_L1))\n",
    "print('Recall score for L1 Regulation: ', recall_score(y_test, predicted_L1))\n",
    "print('F-1 score for L1 Regulation:', f1_score(y_test, predicted_L1))\n",
    "\n",
    "# L1 ROC Curve\n",
    "score_L1 = clf_L1.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score_L1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for L1 Regularized Logistic Regression')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.01)\n",
    "plt.show()\n",
    "\n",
    "# Determine regulation strength for L2 regulation\n",
    "clf_L2 = LogisticRegressionCV(random_state=42, Cs=REG_STRENGTH_OPTIONS, cv=5, penalty='l2', scoring='accuracy', solver = 'liblinear').fit(X_train, y_train)\n",
    "L2_reg_strength = 1/clf_L2.C_ # Regulization strength is inverse of optimal Cs\n",
    "predicted_L2 = clf_L2.predict(X_test)\n",
    "\n",
    "# Display L2 Stats\n",
    "print('\\nOptimal regularization strength for L2 regulation: ', L2_reg_strength)\n",
    "print('Accuracy with L2 Regulation: ', clf_L2.score(X_test, y_test))\n",
    "print('Average precision-recall score for L2 Regulation:', average_precision_score(y_test, predicted_L2))\n",
    "print('Precision score for L2 Regulation: ', precision_score(y_test, predicted_L2))\n",
    "print('Recall score for L2 Regulation: ', recall_score(y_test, predicted_L2))\n",
    "print('F-1 score for L2 Regulation:', f1_score(y_test, predicted_L2))\n",
    "\n",
    "# L2 ROC Curve\n",
    "score_L2 = clf_L2.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score_L2)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for L2 Regularized Logistic Regression')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGNn6K_exvyB"
   },
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NkfS2HZxvyB"
   },
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Train a Naive Bayes Gaussian classifier on the reduced TFIDF training set from problem 3\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = GaussianNB().fit(W_nmf_train_reduced, twenty_train.target)\n",
    "# clf2 = MultinomialNB().fit(W_nmf_train_reduced, twenty_train.target)\n",
    "clf = GaussianNB().fit(W_nmf_train_reduced, twenty_train_binary_labels)\n",
    "clf2 = MultinomialNB().fit(W_nmf_train_reduced, twenty_train_binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQN9jIzvxvyE",
    "outputId": "6308ec42-fcf7-4348-a564-562c886cda29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB Gaussian: 0.9374603174603174\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Generate predictions for test set\n",
    "\n",
    "predicted = clf.predict(W_nmf_test_reduced)\n",
    "correct = 0\n",
    "for i, category in enumerate(predicted):\n",
    "    if category == twenty_test_binary_labels[i]:\n",
    "        correct += 1\n",
    "#     if i < 5:\n",
    "#         print('{} =? {}'.format(twenty_test.target_names[category], twenty_test.target_names[twenty_test.target[i]]))\n",
    "#     elif i == 5:\n",
    "#         print('...\\n')\n",
    "print('Accuracy of NB Gaussian: {}'.format(correct / W_nmf_test_reduced.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0IChMnAxvyH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NB Gaussian: 0.94\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################\n",
    "# Generate predictions for test set\n",
    "\n",
    "predicted = clf2.predict(W_nmf_test_reduced)\n",
    "correct = 0\n",
    "for i, category in enumerate(predicted):\n",
    "    if category == twenty_test_binary_labels[i]:\n",
    "        correct += 1\n",
    "#     if i < 5:\n",
    "#         print('{} =? {}'.format(twenty_test.target_names[category], twenty_test.target_names[twenty_test.target[i]]))\n",
    "#     elif i == 5:\n",
    "#         print('...\\n')\n",
    "print('Accuracy of NB Gaussian: {}'.format(correct / W_nmf_test_reduced.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "## Custom Transformers for Grid Search\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "# The lemmatizer is actually pretty complicated, it needs Parts of Speech (POS) tags\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "# nltk.download('punkt')#, if you need \"tokenizers/punkt/english.pickle\", choose it\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "class Importer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, remove=None):\n",
    "        self.remove = remove\n",
    "\n",
    "    def transform(self, raw_documents, *_):\n",
    "        if self.remove is not None:\n",
    "            if 'headers' in self.remove:\n",
    "                raw_documents = [self.strip_newsgroup_header(text) for text in raw_documents]\n",
    "            if 'footers' in self.remove:\n",
    "                raw_documents = [self.strip_newsgroup_footer(text) for text in raw_documents]\n",
    "\n",
    "        return raw_documents\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "    ## Taken from twenty_newsgroups.py\n",
    "    @staticmethod\n",
    "    def strip_newsgroup_header(text):\n",
    "        \"\"\"\n",
    "        Given text in \"news\" format, strip the headers, by removing everything\n",
    "        before the first blank line.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : string\n",
    "            The text from which to remove the signature block.\n",
    "        \"\"\"\n",
    "        _before, _blankline, after = text.partition('\\n\\n')\n",
    "        return after\n",
    "\n",
    "    _QUOTE_RE = re.compile(r'(writes in|writes:|wrote:|says:|said:'\n",
    "                           r'|^In article|^Quoted from|^\\||^>)')\n",
    "\n",
    "    ## Taken from twenty_newsgroups.py\n",
    "    @staticmethod\n",
    "    def strip_newsgroup_footer(text):\n",
    "        \"\"\"\n",
    "        Given text in \"news\" format, attempt to remove a signature block.\n",
    "\n",
    "        As a rough heuristic, we assume that signatures are set apart by either\n",
    "        a blank line or a line made of hyphens, and that it is the last such line\n",
    "        in the file (disregarding blank lines at the end).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : string\n",
    "            The text from which to remove the signature block.\n",
    "        \"\"\"\n",
    "        lines = text.strip().split('\\n')\n",
    "        for line_num in range(len(lines) - 1, -1, -1):\n",
    "            line = lines[line_num]\n",
    "            if line.strip().strip('-') == '':\n",
    "                break\n",
    "\n",
    "        if line_num > 0:\n",
    "            return '\\n'.join(lines[:line_num])\n",
    "        else:\n",
    "            return text\n",
    "\n",
    "\n",
    "class Lemmatizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, enabled=True):\n",
    "        self.enabled = enabled\n",
    "        self.wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "\n",
    "    def transform(self, raw_documents, *_):\n",
    "        if self.enabled:\n",
    "            return self._lemmatize_and_filter(raw_documents)\n",
    "        else:\n",
    "            return raw_documents\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "    ##################################################################\n",
    "    # supporting functions:\n",
    "    def _penn2morphy(self, penntag):\n",
    "        \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "        morphy_tag = {'NN': 'n', 'JJ': 'a',\n",
    "                      'VB': 'v', 'RB': 'r'}\n",
    "        try:\n",
    "            return morphy_tag[penntag[:2]]\n",
    "        except:\n",
    "            return 'n'\n",
    "\n",
    "    # def lemmatize_sent(list_word, wnl):\n",
    "    #     # Text input is string, returns array of lowercased strings(words).\n",
    "    #     return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag))\n",
    "    #             for word, tag in pos_tag(list_word)]\n",
    "\n",
    "    def _lemmatize_training(self, text):\n",
    "        # Text input is string, returns array of lowercased strings(words).\n",
    "        return [self.wnl.lemmatize(word.lower(), pos=self._penn2morphy(tag))\n",
    "                for word, tag in pos_tag(nltk.word_tokenize(text))]\n",
    "\n",
    "    def _filter_numbers(self, text_array):\n",
    "        # Filter out any numbers found in the array of strings\n",
    "        output = []\n",
    "        for s in text_array:\n",
    "            if not s.isdigit():\n",
    "                # if not a digit...\n",
    "                try:\n",
    "                    # if a float, filter out\n",
    "                    float(s)\n",
    "                except ValueError:\n",
    "                    # if not a float, add to output\n",
    "                    output.append(s)\n",
    "            else:\n",
    "                # if a digit, filter out\n",
    "                pass\n",
    "        return output\n",
    "\n",
    "    def _array_to_string(self, text_array, delimeter=\"\"):\n",
    "        # Converts an array back into a string of words using the provided delimeter to add between each word\n",
    "        output = \"\"\n",
    "        for s in text_array:\n",
    "            output = output + delimeter + s\n",
    "        return output\n",
    "\n",
    "    def _lemmatize_and_filter(self, documents):\n",
    "        # Performs lemmatization, and number filtering on the given documents\n",
    "        lemmatized_data = []\n",
    "        for i in documents:\n",
    "            # lemmatize the document:\n",
    "            training_tagged = pos_tag(nltk.word_tokenize(i))\n",
    "            lemmatized_array = self._lemmatize_training(i)\n",
    "\n",
    "            # remove numbers from document:\n",
    "            filtered_array = self._filter_numbers(lemmatized_array)\n",
    "\n",
    "            # reassemble back to string:\n",
    "            lemmatized_string = self._array_to_string(filtered_array, ' ')\n",
    "\n",
    "            # add to final data list\n",
    "            # print(lemmatized_string)\n",
    "            lemmatized_data.append(lemmatized_string)\n",
    "\n",
    "        return lemmatized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='C:\\\\Users\\\\zharr\\\\AppData\\\\Local\\\\Temp\\\\tmpga4_4s23'\", use \"location='C:\\\\Users\\\\zharr\\\\AppData\\\\Local\\\\Temp\\\\tmpga4_4s23'\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Importer(remove=None), [ 'From: rschmitt@shearson.com (Robert Schmitt)\\n'\n",
      "  'Subject: Re: Please Recommend 3D Graphics Library F\\n'\n",
      "  'Reply-To: rschmitt@shearson.com\\n'\n",
      "  'Organization: Lehman Brothers, Inc.\\n'\n",
      "  'Lines: 9\\n'\n",
      "  '\\n'\n",
      "  'What hardware do plan to run on?  Workstation or PC?  Cost level?\\n'\n",
      "  'Run-time licensing needs?\\n'\n",
      "  '\\n'\n",
      "  'Bob\\n'\n",
      "  '------------------------------------------------------------------\\n'\n",
      "  'Robert A. Schmitt | Applied Derivatives Technology | Lehman Brothers\\n'\n",
      "  'rschmitt@shearson.com\\n'\n",
      "  '\\n'\n",
      "  '\\n',\n",
      "  'From: mori@volga.mfd.cs.fujitsu.co.jp (Tsuyoshi Mori)\\n'\n",
      "  'Subject: I want use DeskJet on System7\\n'\n",
      "  'Organization: FUJITSU.Ltd., Kawasaki, Japan.\\n'\n",
      "  'Lines: 15\\n'\n",
      "  'Di..., \n",
      "array([0., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.7s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Lemmatizer(enabled=False), [ 'From: rschmitt@shearson.com (Robert Schmitt)\\n'\n",
      "  'Subject: Re: Please Recommend 3D Graphics Library F\\n'\n",
      "  'Reply-To: rschmitt@shearson.com\\n'\n",
      "  'Organization: Lehman Brothers, Inc.\\n'\n",
      "  'Lines: 9\\n'\n",
      "  '\\n'\n",
      "  'What hardware do plan to run on?  Workstation or PC?  Cost level?\\n'\n",
      "  'Run-time licensing needs?\\n'\n",
      "  '\\n'\n",
      "  'Bob\\n'\n",
      "  '------------------------------------------------------------------\\n'\n",
      "  'Robert A. Schmitt | Applied Derivatives Technology | Lehman Brothers\\n'\n",
      "  'rschmitt@shearson.com\\n'\n",
      "  '\\n'\n",
      "  '\\n',\n",
      "  'From: mori@volga.mfd.cs.fujitsu.co.jp (Tsuyoshi Mori)\\n'\n",
      "  'Subject: I want use DeskJet on System7\\n'\n",
      "  'Organization: FUJITSU.Ltd., Kawasaki, Japan.\\n'\n",
      "  'Lines: 15\\n'\n",
      "  'Di..., \n",
      "array([0., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: rschmitt@shearson.com (Robert Schmitt)\\n'\n",
      "  'Subject: Re: Please Recommend 3D Graphics Library F\\n'\n",
      "  'Reply-To: rschmitt@shearson.com\\n'\n",
      "  'Organization: Lehman Brothers, Inc.\\n'\n",
      "  'Lines: 9\\n'\n",
      "  '\\n'\n",
      "  'What hardware do plan to run on?  Workstation or PC?  Cost level?\\n'\n",
      "  'Run-time licensing needs?\\n'\n",
      "  '\\n'\n",
      "  'Bob\\n'\n",
      "  '------------------------------------------------------------------\\n'\n",
      "  'Robert A. Schmitt | Applied Derivatives Technology | Lehman Brothers\\n'\n",
      "  'rschmitt@shearson.com\\n'\n",
      "  '\\n'\n",
      "  '\\n',\n",
      "  'From: mori@volga.mfd.cs.fujitsu.co.jp (Tsuyoshi Mori)\\n'\n",
      "  'Subject: I want use DeskJet on System7\\n'\n",
      "  'Organization: FUJITSU.Ltd., Kawasaki, Japan.\\n'\n",
      "  'Lines: 15\\n'\n",
      "  'Di..., \n",
      "array([0., ..., 0.]), None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\pipeline.py:230: UserWarning: Persisting input arguments took 12.23s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 4.7s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x68241 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 388188 stored elements in Compressed Sparse Row format>, \n",
      "array([0., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3785x68241 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 388188 stored elements in Compressed Sparse Row format>, \n",
      "array([0., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Importer(remove=None), [ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Lemmatizer(enabled=False), [ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\pipeline.py:230: UserWarning: Persisting input arguments took 12.39s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 4.7s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x67397 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 383315 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3785x67397 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 383315 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Importer(remove=None), [ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Lemmatizer(enabled=False), [ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\pipeline.py:230: UserWarning: Persisting input arguments took 11.99s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 4.7s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x67706 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 387422 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3785x67706 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 387422 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Importer(remove=None), [ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Lemmatizer(enabled=False), [ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 0.]), None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\pipeline.py:230: UserWarning: Persisting input arguments took 12.81s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 4.8s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x70543 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 389512 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3786x70543 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 389512 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Importer(remove=None), [ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 1.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(Lemmatizer(enabled=False), [ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 1.]), None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "array([1., ..., 1.]), None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\pipeline.py:230: UserWarning: Persisting input arguments took 12.36s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 4.8s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x70287 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 390287 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 1.]), None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3787x70287 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 390287 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 1.]), None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\bc64d833e6b3db3c1a80e7ac2b1000e8\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\82140bd2f442b4c2760965176386c41c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6010b150af790472a9d8cabbab28259c\n",
      "___________________________________fit_transform_one cache loaded - 1.1s, 0.0min\n",
      "[Memory]1.3s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b49d4c2b3b4e5342021f1dabf42e81ae\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3785x68241 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 388188 stored elements in Compressed Sparse Row format>, \n",
      "array([0., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 1.3s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\499bec3abc0e0a7a4342c2112558a22b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\2c2dbd4c489963c91a680ae0c7fe9176\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\57aca6fa0f766b384361fe9755219eaa\n",
      "___________________________________fit_transform_one cache loaded - 1.1s, 0.0min\n",
      "[Memory]1.3s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\de466f4436f78f1546a3d7ac511d6c74\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3785x67397 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 383315 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 1.2s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\02b290dccb3325f39b8f06db3c8a09fb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\2f7e4e3c2661e7ed367db9a3890e279b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9afd28b242187c2c93612ab980fb44c0\n",
      "___________________________________fit_transform_one cache loaded - 1.1s, 0.0min\n",
      "[Memory]1.4s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\43c08c0965437fc54b434700434d1a8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3785x67706 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 387422 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 1.2s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\eed1352d6e39439e597884e7b3ac7430\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\2ec8322ae1cec1ed7392c3c64b178eac\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\504705cd35a6b6d516069d2948c4bbeb\n",
      "___________________________________fit_transform_one cache loaded - 1.2s, 0.0min\n",
      "[Memory]1.4s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\08c87dd11ed0e2a62061145a715e6068\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3786x70543 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 389512 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 1.3s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\3aa0990cb487d8cb8e038672b786ccf4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\25f9808b3fbf73ba056636e8d4df7b23\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\9038d96c17286d6d4a632ae325d69004\n",
      "___________________________________fit_transform_one cache loaded - 1.2s, 0.0min\n",
      "[Memory]1.4s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\f7c03bfe2b2bd39213b12e689e312b21\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=None, tol=0.0), \n",
      "<3787x70287 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 390287 stored elements in Compressed Sparse Row format>, \n",
      "array([1., ..., 1.]), None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 1.2s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\bc64d833e6b3db3c1a80e7ac2b1000e8\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\82140bd2f442b4c2760965176386c41c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\6010b150af790472a9d8cabbab28259c\n",
      "___________________________________fit_transform_one cache loaded - 1.1s, 0.0min\n",
      "[Memory]1.4s, 0.0min    : Loading _fit_transform_one from C:\\Users\\zharr\\AppData\\Local\\Temp\\tmpga4_4s23\\joblib\\sklearn\\pipeline\\_fit_transform_one\\b49d4c2b3b4e5342021f1dabf42e81ae\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
      "  n_components=10, random_state=None, shuffle=False, solver='cd',\n",
      "  tol=0.0001, verbose=0), \n",
      "<3785x68241 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 388188 stored elements in Compressed Sparse Row format>, \n",
      "array([0., ..., 0.]), None)\n",
      "________________________________________________fit_transform_one - 1.9s, 0.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bac10af73f59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwenty_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtwenty_train_binary_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcachedir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    823\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[1;32m--> 572\u001b[1;33m                                   is_multimetric)\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \"\"\"\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \"\"\"\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1066\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1067\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    306\u001b[0m                                                tokenize)\n\u001b[0;32m    307\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 308\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ########################################################################################################################\n",
    "# # Change labels into binary based on two well separated classes: Computer (labels 0-3) and Recreational (labels 4-7).\n",
    "# twenty_train_binary_labels = np.zeros(len(twenty_train.target))\n",
    "# for k in range(len(twenty_train.target)):\n",
    "#     if twenty_train.target[k] >= 4:\n",
    "#         twenty_train_binary_labels[k] = 1\n",
    "# twenty_test_binary_labels = np.zeros(len(twenty_test.target))\n",
    "# for k in range(len(twenty_test.target)):\n",
    "#     if twenty_test.target[k] >= 4:\n",
    "#         twenty_test_binary_labels[k] = 1\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "\n",
    "# used to cache results\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.externals.joblib import Memory\n",
    "# print(__doc__)\n",
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('import', Importer(remove=None)),\n",
    "    ('lemm', Lemmatizer(enabled=True)),\n",
    "    ('vect', CountVectorizer(min_df=1, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(random_state=0)),\n",
    "    ('clf', GaussianNB()),\n",
    "],\n",
    "memory=memory\n",
    ")\n",
    "\n",
    "N_FEATURES_OPTIONS = [10, 50]\n",
    "C_OPTIONS = [0.1, 1, 10]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'import__remove': [None, ['headers', 'footers']],\n",
    "        'lemm__enabled': [False, True],\n",
    "        'vect__min_df': [3, 5],\n",
    "        'reduce_dim': [TruncatedSVD(), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'clf': [LinearSVC()],\n",
    "        'clf__C': C_OPTIONS\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipeline, cv=5, n_jobs=1, param_grid=param_grid, scoring='accuracy')\n",
    "grid.fit(twenty_train.data, twenty_train_binary_labels)\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\zharr\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_import__remove</th>\n",
       "      <th>param_lemm__enabled</th>\n",
       "      <th>param_reduce_dim</th>\n",
       "      <th>param_reduce_dim__n_components</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.487636</td>\n",
       "      <td>0.238821</td>\n",
       "      <td>0.962595</td>\n",
       "      <td>0.961486</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960929</td>\n",
       "      <td>0.958256</td>\n",
       "      <td>0.968288</td>\n",
       "      <td>0.962229</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.961975</td>\n",
       "      <td>0.225747</td>\n",
       "      <td>0.011622</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.967219</td>\n",
       "      <td>0.264457</td>\n",
       "      <td>0.970414</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>0.971995</td>\n",
       "      <td>0.973573</td>\n",
       "      <td>0.972530</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.974386</td>\n",
       "      <td>0.077595</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.021458</td>\n",
       "      <td>0.268467</td>\n",
       "      <td>0.940194</td>\n",
       "      <td>0.940564</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946146</td>\n",
       "      <td>0.938441</td>\n",
       "      <td>0.942918</td>\n",
       "      <td>0.949551</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.937153</td>\n",
       "      <td>1.642200</td>\n",
       "      <td>0.010928</td>\n",
       "      <td>0.004824</td>\n",
       "      <td>0.006110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.245995</td>\n",
       "      <td>0.480431</td>\n",
       "      <td>0.931741</td>\n",
       "      <td>0.927833</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947202</td>\n",
       "      <td>0.942668</td>\n",
       "      <td>0.932347</td>\n",
       "      <td>0.930798</td>\n",
       "      <td>0.934392</td>\n",
       "      <td>0.916821</td>\n",
       "      <td>8.319888</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>0.011973</td>\n",
       "      <td>0.008718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.682118</td>\n",
       "      <td>0.198526</td>\n",
       "      <td>0.935757</td>\n",
       "      <td>0.936708</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936642</td>\n",
       "      <td>0.937384</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.932664</td>\n",
       "      <td>0.442248</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.623997</td>\n",
       "      <td>0.216139</td>\n",
       "      <td>0.952663</td>\n",
       "      <td>0.957048</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952482</td>\n",
       "      <td>0.954029</td>\n",
       "      <td>0.948203</td>\n",
       "      <td>0.958796</td>\n",
       "      <td>0.960847</td>\n",
       "      <td>0.956166</td>\n",
       "      <td>0.354294</td>\n",
       "      <td>0.010978</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.002150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.320409</td>\n",
       "      <td>0.217080</td>\n",
       "      <td>0.934277</td>\n",
       "      <td>0.932800</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935586</td>\n",
       "      <td>0.941612</td>\n",
       "      <td>0.936575</td>\n",
       "      <td>0.931062</td>\n",
       "      <td>0.934392</td>\n",
       "      <td>0.918405</td>\n",
       "      <td>0.468527</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.007933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37.950579</td>\n",
       "      <td>0.375455</td>\n",
       "      <td>0.935123</td>\n",
       "      <td>0.932745</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931362</td>\n",
       "      <td>0.929194</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.926043</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.938474</td>\n",
       "      <td>8.259973</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.006603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.468076</td>\n",
       "      <td>0.249059</td>\n",
       "      <td>0.965554</td>\n",
       "      <td>0.963810</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.969345</td>\n",
       "      <td>0.963022</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.963824</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.001807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.485586</td>\n",
       "      <td>0.264089</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.975697</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.975165</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>0.976492</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.975970</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.468438</td>\n",
       "      <td>0.268312</td>\n",
       "      <td>0.955199</td>\n",
       "      <td>0.950814</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958817</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>0.959831</td>\n",
       "      <td>0.956418</td>\n",
       "      <td>0.958730</td>\n",
       "      <td>0.946924</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.003191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.490639</td>\n",
       "      <td>0.476573</td>\n",
       "      <td>0.949493</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954593</td>\n",
       "      <td>0.950859</td>\n",
       "      <td>0.951374</td>\n",
       "      <td>0.948759</td>\n",
       "      <td>0.950265</td>\n",
       "      <td>0.939530</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.004013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.267450</td>\n",
       "      <td>0.204444</td>\n",
       "      <td>0.949281</td>\n",
       "      <td>0.952716</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952482</td>\n",
       "      <td>0.951651</td>\n",
       "      <td>0.946089</td>\n",
       "      <td>0.953777</td>\n",
       "      <td>0.954497</td>\n",
       "      <td>0.948508</td>\n",
       "      <td>0.034555</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>0.006111</td>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.294739</td>\n",
       "      <td>0.240825</td>\n",
       "      <td>0.967244</td>\n",
       "      <td>0.970889</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963041</td>\n",
       "      <td>0.968296</td>\n",
       "      <td>0.960888</td>\n",
       "      <td>0.971738</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.972274</td>\n",
       "      <td>0.033119</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.001566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.271338</td>\n",
       "      <td>0.219448</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.939825</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940866</td>\n",
       "      <td>0.944518</td>\n",
       "      <td>0.942918</td>\n",
       "      <td>0.936080</td>\n",
       "      <td>0.939683</td>\n",
       "      <td>0.933985</td>\n",
       "      <td>0.022304</td>\n",
       "      <td>0.012211</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>0.004353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.289022</td>\n",
       "      <td>0.370687</td>\n",
       "      <td>0.948859</td>\n",
       "      <td>0.947802</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939810</td>\n",
       "      <td>0.943461</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.942155</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.949300</td>\n",
       "      <td>0.023368</td>\n",
       "      <td>0.012241</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.006117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.468181</td>\n",
       "      <td>0.244173</td>\n",
       "      <td>0.966822</td>\n",
       "      <td>0.965395</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966209</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.969345</td>\n",
       "      <td>0.965135</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.963295</td>\n",
       "      <td>0.033132</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.002717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.521880</td>\n",
       "      <td>0.261826</td>\n",
       "      <td>0.972950</td>\n",
       "      <td>0.978075</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974657</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.972516</td>\n",
       "      <td>0.979662</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.976763</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.001304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.476721</td>\n",
       "      <td>0.264500</td>\n",
       "      <td>0.959848</td>\n",
       "      <td>0.958686</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>0.956407</td>\n",
       "      <td>0.959831</td>\n",
       "      <td>0.964078</td>\n",
       "      <td>0.964021</td>\n",
       "      <td>0.955110</td>\n",
       "      <td>0.021873</td>\n",
       "      <td>0.010419</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>0.003162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.516557</td>\n",
       "      <td>0.470850</td>\n",
       "      <td>0.961961</td>\n",
       "      <td>0.960059</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963041</td>\n",
       "      <td>0.960370</td>\n",
       "      <td>0.964059</td>\n",
       "      <td>0.961965</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.959071</td>\n",
       "      <td>0.029842</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.002948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.267040</td>\n",
       "      <td>0.204160</td>\n",
       "      <td>0.960693</td>\n",
       "      <td>0.961275</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965153</td>\n",
       "      <td>0.962483</td>\n",
       "      <td>0.960888</td>\n",
       "      <td>0.963286</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.957222</td>\n",
       "      <td>0.037108</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.002117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.327578</td>\n",
       "      <td>0.241073</td>\n",
       "      <td>0.971682</td>\n",
       "      <td>0.976173</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.967230</td>\n",
       "      <td>0.976492</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.976499</td>\n",
       "      <td>0.035656</td>\n",
       "      <td>0.051580</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.288924</td>\n",
       "      <td>0.216852</td>\n",
       "      <td>0.948648</td>\n",
       "      <td>0.948595</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947202</td>\n",
       "      <td>0.951915</td>\n",
       "      <td>0.945032</td>\n",
       "      <td>0.943740</td>\n",
       "      <td>0.951323</td>\n",
       "      <td>0.946924</td>\n",
       "      <td>0.039676</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.003112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.327435</td>\n",
       "      <td>0.373320</td>\n",
       "      <td>0.962806</td>\n",
       "      <td>0.961644</td>\n",
       "      <td>LinearSVC(C=10, class_weight=None, dual=True, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[headers, footers]</td>\n",
       "      <td>False</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init=Non...</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958817</td>\n",
       "      <td>0.960106</td>\n",
       "      <td>0.956660</td>\n",
       "      <td>0.959588</td>\n",
       "      <td>0.969312</td>\n",
       "      <td>0.961183</td>\n",
       "      <td>0.035291</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       19.487636         0.238821         0.962595          0.961486   \n",
       "1        2.967219         0.264457         0.970414          0.972316   \n",
       "2        5.021458         0.268467         0.940194          0.940564   \n",
       "3       51.245995         0.480431         0.931741          0.927833   \n",
       "4       16.682118         0.198526         0.935757          0.936708   \n",
       "5        2.623997         0.216139         0.952663          0.957048   \n",
       "6        3.320409         0.217080         0.934277          0.932800   \n",
       "7       37.950579         0.375455         0.935123          0.932745   \n",
       "8        1.468076         0.249059         0.965554          0.963810   \n",
       "9        1.485586         0.264089         0.971893          0.975697   \n",
       "10       1.468438         0.268312         0.955199          0.950814   \n",
       "11       1.490639         0.476573         0.949493          0.946429   \n",
       "12       1.267450         0.204444         0.949281          0.952716   \n",
       "13       1.294739         0.240825         0.967244          0.970889   \n",
       "14       1.271338         0.219448         0.940828          0.939825   \n",
       "15       1.289022         0.370687         0.948859          0.947802   \n",
       "16       1.468181         0.244173         0.966822          0.965395   \n",
       "17       1.521880         0.261826         0.972950          0.978075   \n",
       "18       1.476721         0.264500         0.959848          0.958686   \n",
       "19       1.516557         0.470850         0.961961          0.960059   \n",
       "20       1.267040         0.204160         0.960693          0.961275   \n",
       "21       1.327578         0.241073         0.971682          0.976173   \n",
       "22       1.288924         0.216852         0.948648          0.948595   \n",
       "23       1.327435         0.373320         0.962806          0.961644   \n",
       "\n",
       "                                            param_clf param_clf__C  \\\n",
       "0   LinearSVC(C=10, class_weight=None, dual=True, ...          0.1   \n",
       "1   LinearSVC(C=10, class_weight=None, dual=True, ...          0.1   \n",
       "2   LinearSVC(C=10, class_weight=None, dual=True, ...          0.1   \n",
       "3   LinearSVC(C=10, class_weight=None, dual=True, ...          0.1   \n",
       "4   LinearSVC(C=10, class_weight=None, dual=True, ...          0.1   \n",
       "5   LinearSVC(C=10, class_weight=None, dual=True, ...          0.1   \n",
       "6   LinearSVC(C=10, class_weight=None, dual=True, ...          0.1   \n",
       "7   LinearSVC(C=10, class_weight=None, dual=True, ...          0.1   \n",
       "8   LinearSVC(C=10, class_weight=None, dual=True, ...            1   \n",
       "9   LinearSVC(C=10, class_weight=None, dual=True, ...            1   \n",
       "10  LinearSVC(C=10, class_weight=None, dual=True, ...            1   \n",
       "11  LinearSVC(C=10, class_weight=None, dual=True, ...            1   \n",
       "12  LinearSVC(C=10, class_weight=None, dual=True, ...            1   \n",
       "13  LinearSVC(C=10, class_weight=None, dual=True, ...            1   \n",
       "14  LinearSVC(C=10, class_weight=None, dual=True, ...            1   \n",
       "15  LinearSVC(C=10, class_weight=None, dual=True, ...            1   \n",
       "16  LinearSVC(C=10, class_weight=None, dual=True, ...           10   \n",
       "17  LinearSVC(C=10, class_weight=None, dual=True, ...           10   \n",
       "18  LinearSVC(C=10, class_weight=None, dual=True, ...           10   \n",
       "19  LinearSVC(C=10, class_weight=None, dual=True, ...           10   \n",
       "20  LinearSVC(C=10, class_weight=None, dual=True, ...           10   \n",
       "21  LinearSVC(C=10, class_weight=None, dual=True, ...           10   \n",
       "22  LinearSVC(C=10, class_weight=None, dual=True, ...           10   \n",
       "23  LinearSVC(C=10, class_weight=None, dual=True, ...           10   \n",
       "\n",
       "   param_import__remove param_lemm__enabled  \\\n",
       "0                  None               False   \n",
       "1                  None               False   \n",
       "2                  None               False   \n",
       "3                  None               False   \n",
       "4    [headers, footers]               False   \n",
       "5    [headers, footers]               False   \n",
       "6    [headers, footers]               False   \n",
       "7    [headers, footers]               False   \n",
       "8                  None               False   \n",
       "9                  None               False   \n",
       "10                 None               False   \n",
       "11                 None               False   \n",
       "12   [headers, footers]               False   \n",
       "13   [headers, footers]               False   \n",
       "14   [headers, footers]               False   \n",
       "15   [headers, footers]               False   \n",
       "16                 None               False   \n",
       "17                 None               False   \n",
       "18                 None               False   \n",
       "19                 None               False   \n",
       "20   [headers, footers]               False   \n",
       "21   [headers, footers]               False   \n",
       "22   [headers, footers]               False   \n",
       "23   [headers, footers]               False   \n",
       "\n",
       "                                     param_reduce_dim  \\\n",
       "0   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "1   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "2   NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "3   NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "4   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "5   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "6   NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "7   NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "8   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "9   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "10  NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "11  NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "12  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "13  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "14  NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "15  NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "16  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "17  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "18  NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "19  NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "20  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "21  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "22  NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "23  NMF(alpha=0.0, beta_loss='frobenius', init=Non...   \n",
       "\n",
       "   param_reduce_dim__n_components       ...        split2_test_score  \\\n",
       "0                              10       ...                 0.960929   \n",
       "1                              50       ...                 0.968321   \n",
       "2                              10       ...                 0.946146   \n",
       "3                              50       ...                 0.947202   \n",
       "4                              10       ...                 0.936642   \n",
       "5                              50       ...                 0.952482   \n",
       "6                              10       ...                 0.935586   \n",
       "7                              50       ...                 0.931362   \n",
       "8                              10       ...                 0.967265   \n",
       "9                              50       ...                 0.971489   \n",
       "10                             10       ...                 0.958817   \n",
       "11                             50       ...                 0.954593   \n",
       "12                             10       ...                 0.952482   \n",
       "13                             50       ...                 0.963041   \n",
       "14                             10       ...                 0.940866   \n",
       "15                             50       ...                 0.939810   \n",
       "16                             10       ...                 0.966209   \n",
       "17                             50       ...                 0.974657   \n",
       "18                             10       ...                 0.967265   \n",
       "19                             50       ...                 0.963041   \n",
       "20                             10       ...                 0.965153   \n",
       "21                             50       ...                 0.972545   \n",
       "22                             10       ...                 0.947202   \n",
       "23                             50       ...                 0.958817   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0             0.958256           0.968288            0.962229   \n",
       "1             0.971995           0.973573            0.972530   \n",
       "2             0.938441           0.942918            0.949551   \n",
       "3             0.942668           0.932347            0.930798   \n",
       "4             0.937384           0.930233            0.936609   \n",
       "5             0.954029           0.948203            0.958796   \n",
       "6             0.941612           0.936575            0.931062   \n",
       "7             0.929194           0.930233            0.926043   \n",
       "8             0.964333           0.969345            0.963022   \n",
       "9             0.975165           0.970402            0.976492   \n",
       "10            0.948745           0.959831            0.956418   \n",
       "11            0.950859           0.951374            0.948759   \n",
       "12            0.951651           0.946089            0.953777   \n",
       "13            0.968296           0.960888            0.971738   \n",
       "14            0.944518           0.942918            0.936080   \n",
       "15            0.943461           0.941860            0.942155   \n",
       "16            0.968032           0.969345            0.965135   \n",
       "17            0.978071           0.972516            0.979662   \n",
       "18            0.956407           0.959831            0.964078   \n",
       "19            0.960370           0.964059            0.961965   \n",
       "20            0.962483           0.960888            0.963286   \n",
       "21            0.975694           0.967230            0.976492   \n",
       "22            0.951915           0.945032            0.943740   \n",
       "23            0.960106           0.956660            0.959588   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.968254            0.961975      0.225747        0.011622   \n",
       "1            0.970370            0.974386      0.077595        0.010639   \n",
       "2            0.942857            0.937153      1.642200        0.010928   \n",
       "3            0.934392            0.916821      8.319888        0.018547   \n",
       "4            0.942857            0.932664      0.442248        0.010393   \n",
       "5            0.960847            0.956166      0.354294        0.010978   \n",
       "6            0.934392            0.918405      0.468527        0.010654   \n",
       "7            0.952381            0.938474      8.259973        0.011617   \n",
       "8            0.968254            0.963824      0.027534        0.011875   \n",
       "9            0.971429            0.975970      0.027899        0.010097   \n",
       "10           0.958730            0.946924      0.029883        0.013460   \n",
       "11           0.950265            0.939530      0.031525        0.018341   \n",
       "12           0.954497            0.948508      0.034555        0.012212   \n",
       "13           0.974603            0.972274      0.033119        0.051531   \n",
       "14           0.939683            0.933985      0.022304        0.012211   \n",
       "15           0.962963            0.949300      0.023368        0.012241   \n",
       "16           0.970370            0.963295      0.033132        0.010275   \n",
       "17           0.971429            0.976763      0.015135        0.011619   \n",
       "18           0.964021            0.955110      0.021873        0.010419   \n",
       "19           0.961905            0.959071      0.029842        0.015870   \n",
       "20           0.962963            0.957222      0.037108        0.010924   \n",
       "21           0.974603            0.976499      0.035656        0.051580   \n",
       "22           0.951323            0.946924      0.039676        0.010544   \n",
       "23           0.969312            0.961183      0.035291        0.004144   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.004819         0.002713  \n",
       "1         0.002401         0.001131  \n",
       "2         0.004824         0.006110  \n",
       "3         0.011973         0.008718  \n",
       "4         0.006229         0.002137  \n",
       "5         0.008235         0.002150  \n",
       "6         0.005599         0.007933  \n",
       "7         0.008789         0.006603  \n",
       "8         0.004135         0.001807  \n",
       "9         0.001966         0.000582  \n",
       "10        0.006271         0.003191  \n",
       "11        0.004185         0.004013  \n",
       "12        0.006111         0.002453  \n",
       "13        0.006505         0.001566  \n",
       "14        0.006443         0.004353  \n",
       "15        0.009560         0.006117  \n",
       "16        0.003294         0.002717  \n",
       "17        0.001447         0.001304  \n",
       "18        0.006075         0.003162  \n",
       "19        0.001758         0.002948  \n",
       "20        0.004828         0.002117  \n",
       "21        0.004972         0.001289  \n",
       "22        0.005490         0.003112  \n",
       "23        0.006275         0.002588  \n",
       "\n",
       "[24 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "proj1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
